{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Install Packages**"
      ],
      "metadata": {
        "id": "6Ej65taz1xmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DLB3q-b-3Ekc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NttcG8ZnNXQT"
      },
      "outputs": [],
      "source": [
        "!python --version\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local\n",
        "\n",
        "!conda init\n",
        "!conda install -q python=3.9\n",
        "!conda create -q --name py39 python=3.9\n",
        "!source  activate py39\n",
        "!python --version\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning-flash"
      ],
      "metadata": {
        "id": "7ltowYFVSwTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'lightning-flash[image]'"
      ],
      "metadata": {
        "id": "2jBw_CwOUFoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation_models_pytorch\n",
        "!pip install tensorboard==2.9.1  # หรือเวอร์ชันที่เหมาะสม\n",
        "!pip install setuptools==59.5.0"
      ],
      "metadata": {
        "id": "GbxDoZqLHTgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Download DataSet**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mnbzeqev1lc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile download.py\n",
        "from icevision.all import *\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "data_url = 'https://s3.amazonaws.com/fast-ai-sample/camvid_tiny.tgz'\n",
        "data = icedata.load_data(data_url,\"data\")\n",
        "\n",
        "\n",
        "destination_dir = os.getcwd()  # ใช้ไดเรกทอรีปัจจุบันในการทำงาน\n",
        "\n",
        "# เคลื่อนย้ายโฟลเดอร์ไปยังไดเรกทอรีปลายทาง\n",
        "shutil.move(str(data), os.path.join(destination_dir, 'data'))\n",
        "\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOu5HWzvdTTJ",
        "outputId": "f5c782a7-5374-4968-e4b4-a22830d24d8b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing download.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python download.py"
      ],
      "metadata": {
        "id": "mtECEiRAdU9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Setup-dataset**"
      ],
      "metadata": {
        "id": "hchiLKmq19EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "folder_path = \"/content/data/camvid_tiny/labels\"  # เปลี่ยนเป็น path ของโฟลเดอร์ของคุณ\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\"_P.png\"):\n",
        "        new_filename = filename.replace(\"_P\", \"\")\n",
        "        old_path = os.path.join(folder_path, filename)\n",
        "        new_path = os.path.join(folder_path, new_filename)\n",
        "        os.rename(old_path, new_path)\n",
        "        print(f\"Renamed: {filename} -> {new_filename}\")\n"
      ],
      "metadata": {
        "id": "DY7lnjAgdX9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile check.py\n",
        "import flash\n",
        "import torch\n",
        "from flash.core.data.utils import download_data\n",
        "from flash.image import SemanticSegmentation, SemanticSegmentationData\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "import os\n",
        "from icevision.all import *\n",
        "import numpy as np\n",
        "codes = np.loadtxt(os.path.join(r\"/content/data/camvid_tiny\",\"codes.txt\"),dtype=str)\n",
        "print(codes)\n",
        "class_map = ClassMap(list(codes))\n",
        "print(class_map)\n",
        "print(class_map.num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frCkmlO1fvSG",
        "outputId": "7f6a7eaf-1852-4321-9c90-b30c6aac9d06"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting check.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python check.py"
      ],
      "metadata": {
        "id": "vLaEbA0Kf67A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train Model**"
      ],
      "metadata": {
        "id": "egv-NaGe2OqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "\n",
        "import flash\n",
        "import torch\n",
        "from flash.core.data.utils import download_data\n",
        "from flash.image import SemanticSegmentation, SemanticSegmentationData\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "import os\n",
        "\n",
        "\n",
        "from icevision.all import *\n",
        "import numpy as np\n",
        "codes = np.loadtxt(os.path.join(r\"/content/data/camvid_tiny\",\"codes.txt\"),dtype=str)\n",
        "class_map = ClassMap(list(codes))\n",
        "\n",
        "# 1. Create the DataModule\n",
        "# The data was generated with the  CARLA self-driving simulator as part of the Kaggle Lyft Udacity Challenge.\n",
        "# More info here: https://www.kaggle.com/kumaresanmanickavelu/lyft-udacity-challenge\n",
        "# download_data(\n",
        "#     \"https://github.com/ongchinkiat/LyftPerceptionChallenge/releases/download/v0.1/carla-capture-20180513A.zip\",\n",
        "#     \"./data\",\n",
        "# )\n",
        "print(SemanticSegmentation.available_backbones('unet'))\n",
        "\n",
        "img_path = os.path.join(r\"/content/data/camvid_tiny/images\")\n",
        "label_path = os.path.join(r\"/content/data/camvid_tiny/labels\")\n",
        "\n",
        "datamodule = SemanticSegmentationData.from_folders(\n",
        "    train_folder=img_path,\n",
        "    train_target_folder=label_path,\n",
        "    val_split=0.1,\n",
        "    transform_kwargs={\"image_size\": (256, 256)},\n",
        "    num_classes=class_map.num_classes,\n",
        "    batch_size=4,\n",
        ")\n",
        "\n",
        "# 2. Build the task\n",
        "model = SemanticSegmentation(\n",
        "    backbone=\"mobilenetv3_large_100\",\n",
        "    head=\"fpn\",\n",
        "    num_classes=datamodule.num_classes,\n",
        ")\n",
        "print(\"Processing training\")\n",
        "trainer = flash.Trainer(\n",
        "    max_epochs=50,\n",
        "    logger=CSVLogger(save_dir='logs/'),\n",
        "    gpus=torch.cuda.device_count(),\n",
        "    precision=16 if torch.cuda.device_count() else 32,\n",
        "#     limit_train_batches=0.1,\n",
        "#     limit_val_batches=0.1,\n",
        ")\n",
        "trainer.finetune(model, datamodule=datamodule, strategy=\"freeze\")\n",
        "trainer.save_checkpoint(\"semantic_segmentation_model_model_type_fpn_bb_mobilenetv3_large_100.pt\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4iGVhy-tqma",
        "outputId": "9911d235-57b8-4c50-9420-0a85cf51db5a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "id": "_9R8frjgfTFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Evaluate Model**"
      ],
      "metadata": {
        "id": "AreZeRxj2fbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ploy.py\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# อ่านข้อมูลจาก CSV\n",
        "csv_path = 'logs/lightning_logs/version_4/metrics.csv'\n",
        "metrics = pd.read_csv(f'{csv_path}')\n",
        "del metrics[\"step\"]\n",
        "metrics.set_index(\"epoch\", inplace=True)\n",
        "\n",
        "# สร้างกราฟเส้นโดยไม่มีแถบความเชื่อมั่น\n",
        "g = sns.relplot(data=metrics, kind=\"line\", errorbar=None)\n",
        "g.fig.set_size_inches(12, 6)  # ปรับขนาดกราฟ\n",
        "plt.grid()  # เพิ่มกริด\n",
        "\n",
        "# บันทึกเป็นไฟล์ PNG\n",
        "plt.savefig(\"metrics_plot.png\")\n",
        "# หรือบันทึกเป็นไฟล์ PDF\n",
        "# plt.savefig(\"metrics_plot.pdf\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1Fo4XBzjO5x",
        "outputId": "ea669558-6462-4a8e-95c5-8623bc45975d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ploy.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ploy.py"
      ],
      "metadata": {
        "id": "m2ljMFlxjvsV"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Test Predict**"
      ],
      "metadata": {
        "id": "vzaEuRKI2WOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test.py\n",
        "import flash\n",
        "from flash.image import SemanticSegmentation, SemanticSegmentationData\n",
        "from flash import Trainer\n",
        "from flash.core.data.io.input import DataKeys\n",
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, glob\n",
        "\n",
        "# Load the model\n",
        "model = SemanticSegmentation.load_from_checkpoint(\"semantic_segmentation_model_model_type_fpn_bb_mobilenetv3_large_100.pt\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    gpus=torch.cuda.device_count(),  # Check the number of available GPUs\n",
        "    precision=16 if torch.cuda.device_count() else 32  # Use precision 16 if GPU is available\n",
        ")\n",
        "\n",
        "# Sample images\n",
        "sample_imgs1 = []\n",
        "sample_imgs2 = glob.glob(\"/content/data/camvid_tiny/images/*.png\")[0:3]\n",
        "sample_imgs = sample_imgs1 + sample_imgs2\n",
        "\n",
        "datamodule = SemanticSegmentationData.from_files(\n",
        "    predict_files=sample_imgs,\n",
        "    batch_size=3\n",
        ")\n",
        "codes = np.loadtxt(os.path.join(r\"/content/data/camvid_tiny\",\"codes.txt\"),dtype=str)\n",
        "class_list = list(codes)\n",
        "# Define class names\n",
        "#class_list = ['Animal', 'Archway', 'Bicyclist', 'Bridge', 'Building', 'Car', 'CartLuggagePram', 'Child', 'Column_Pole', 'Fence', 'LaneMkgsDriv', 'LaneMkgsNonDriv', 'Misc_Text', 'MotorcycleScooter', 'OtherMoving', 'ParkingBlock', 'Pedestrian', 'Road', 'RoadShoulder', 'Sidewalk', 'SignSymbol', 'Sky', 'SUVPickupTruck', 'TrafficCone', 'TrafficLight', 'Train', 'Tree', 'Truck_Bus', 'Tunnel', 'VegetationMisc', 'Void', 'Wall']\n",
        "\n",
        "# Define colors for each class (random example colors)\n",
        "colors = np.random.randint(0, 255, size=(len(class_list), 3))\n",
        "\n",
        "def decode_segmap(image, num_classes, colors):\n",
        "    \"\"\"Decode the segmentation map back to RGB colors.\"\"\"\n",
        "    r = np.zeros_like(image).astype(np.uint8)\n",
        "    g = np.zeros_like(image).astype(np.uint8)\n",
        "    b = np.zeros_like(image).astype(np.uint8)\n",
        "    for l in range(num_classes):\n",
        "        idx = image == l\n",
        "        r[idx] = colors[l, 0]\n",
        "        g[idx] = colors[l, 1]\n",
        "        b[idx] = colors[l, 2]\n",
        "    rgb = np.stack([r, g, b], axis=2)\n",
        "    return rgb\n",
        "\n",
        "# Create the figure and axes\n",
        "fig, axarr = plt.subplots(ncols=2, nrows=len(sample_imgs), figsize=(15, 5 * len(sample_imgs)))\n",
        "\n",
        "# Create a color patch for each class\n",
        "from matplotlib.lines import Line2D\n",
        "legend_elements = [Line2D([0], [0], marker='o', color='w', label=class_name,\n",
        "                         markerfacecolor=colors[i] / 255, markersize=10) for i, class_name in enumerate(class_list)]\n",
        "\n",
        "# Add a legend for the classes\n",
        "fig.legend(handles=legend_elements, loc='center right', bbox_to_anchor=(1.05, 0.5), ncol=1, title=\"Classes\")\n",
        "\n",
        "running_i = 0\n",
        "for preds in trainer.predict(model, datamodule=datamodule, output=\"labels\"):\n",
        "    for pred in preds:\n",
        "        # Convert pred to a numpy array\n",
        "        pred_np = np.array(pred)\n",
        "        decoded_pred = decode_segmap(pred_np, len(class_list), colors)\n",
        "\n",
        "        img = plt.imread(sample_imgs[running_i])\n",
        "        axarr[running_i, 0].imshow(img)\n",
        "        axarr[running_i, 1].imshow(decoded_pred)\n",
        "\n",
        "        # Hide axes for better visualization\n",
        "        axarr[running_i, 1].get_xaxis().set_visible(False)\n",
        "        axarr[running_i, 1].get_yaxis().set_visible(False)\n",
        "        axarr[running_i, 0].get_xaxis().set_visible(False)\n",
        "        axarr[running_i, 0].get_yaxis().set_visible(False)\n",
        "\n",
        "        running_i += 1\n",
        "\n",
        "# Save the figure with the legend\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"predictions_.png\")  # Save all predictions in a single file\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0mQxB22sF7l",
        "outputId": "ec564080-3b79-4a84-8c91-0e865a1f81f2"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py"
      ],
      "metadata": {
        "id": "scnsze_vwECf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list > requirements.txt"
      ],
      "metadata": {
        "id": "PmHUCNKwWd0r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}